---
slug: netkit-ipv6-ebpf
title: "Building a Netkit IPv6 Monitor with eBPF in Go"
authors: [cassamajor]
tags: [netkit, ebpf, golang, ipv6, cilium-ebpf]
---

Netkit is a virtual network device introduced in Linux 6.7 that provides programmable attachment points for eBPF programs. Unlike traditional veth pairs that traverse the entire network stack, netkit lets you intercept packets at the earliest possible moment and make routing decisions before kernel processing.

In this tutorial, we'll build a complete IPv6 packet monitor that creates a netkit device pair, attaches eBPF programs to both interfaces, and streams packet metadata to userspace. By the end, you'll understand how to combine Go's functional options pattern with eBPF's ringbuf for efficient kernel-to-userspace communication.

<!-- truncate -->

## Why Netkit for Packet Processing?

Before diving into code, let's understand why netkit matters for CNF (Cloud-Native Network Function) development.

Traditional packet processing with veth pairs has a fundamental limitation: packets must traverse the full network stack before you can inspect them. This means iptables rules, netfilter hooks, and routing decisions all happen before your code sees the packet.

Netkit changes this equation. When you attach an eBPF program to a netkit device, your code runs *before* the kernel processes the packet. You can:

- **Inspect packets** without stack overhead
- **Make routing decisions** based on custom logic
- **Drop malicious traffic** at the earliest point
- **Redirect packets** to different interfaces

This makes netkit ideal for building high-performance network functions in Kubernetes environments where microseconds matter.

## Step 1: Creating a Netkit Pair

Let's start with the absolute minimum: creating a netkit device pair and bringing it up.

A netkit pair consists of two interfaces: a primary and a peer. Packets sent to one appear on the other, similar to veth. But unlike veth, netkit provides dedicated eBPF attachment points on both sides.

Here's the basic structure using the vishvananda/netlink library:

```go title="main.go"
package main

import (
    "log"

    "github.com/vishvananda/netlink"
)

func main() {
    // Create attributes for the primary interface
    attrs := netlink.NewLinkAttrs()
    attrs.Name = "nk0"

    // Create peer attributes (convention: add "p" suffix)
    peerAttrs := netlink.NewLinkAttrs()
    peerAttrs.Name = "nk0p"

    primary := &netlink.Netkit{
        LinkAttrs: attrs,
        Mode:      netlink.NETKIT_MODE_L3,
    }
    primary.SetPeerAttrs(&peerAttrs)

    if err := netlink.LinkAdd(primary); err != nil {
        log.Fatal(err)
    }
    defer netlink.LinkDel(primary)

    // Bring up both interfaces
    if err := netlink.LinkSetUp(primary); err != nil {
        log.Fatal(err)
    }

    peer, _ := netlink.LinkByName("nk0p")
    if err := netlink.LinkSetUp(peer); err != nil {
        log.Fatal(err)
    }

    log.Println("Netkit pair created! Check with: ip link show nk0")
    select {} // Keep running
}
```

**Why L3 mode?** Netkit supports two modes: L2 (Ethernet frames) and L3 (IP packets). L3 mode skips Ethernet header processing entirely, which is more efficient when you only care about IP-level data. For our IPv6 monitor, L3 mode means we receive raw IPv6 packets without Ethernet encapsulation.

Run this (requires root):

```bash
$ sudo go run main.go &
$ ip link show nk0
123: nk0: <POINTOPOINT,NOARP,UP,LOWER_UP> mtu 1500 ...
```

This works, but the code is already getting verbose. We need error handling, naming conventions, and cleanup logic. Let's wrap it in a clean API.

## Step 2: Designing a Clean Go API

Why do we need an abstraction layer? As the codebase grows, you'll create netkit pairs in multiple places: tests, different programs, configuration scripts. Duplicating the netlink setup code leads to inconsistencies and bugs.

The functional options pattern solves this elegantly. Instead of constructors with many parameters, we define option functions that modify configuration:

```go title="netkit/options.go"
package netkit

import "github.com/vishvananda/netlink"

type config struct {
    mode         netlink.NetkitMode
    scrubPrimary netlink.NetkitScrub
    scrubPeer    netlink.NetkitScrub
}

type Option func(*config)

func defaultConfig() *config {
    return &config{
        mode:         netlink.NETKIT_MODE_L3,
        scrubPrimary: netlink.NETKIT_SCRUB_NONE,
        scrubPeer:    netlink.NETKIT_SCRUB_NONE,
    }
}

func WithL3Mode() Option {
    return func(c *config) {
        c.mode = netlink.NETKIT_MODE_L3
    }
}

func WithL2Mode() Option {
    return func(c *config) {
        c.mode = netlink.NETKIT_MODE_L2
    }
}

func WithNoScrub() Option {
    return func(c *config) {
        c.scrubPrimary = netlink.NETKIT_SCRUB_NONE
        c.scrubPeer = netlink.NETKIT_SCRUB_NONE
    }
}
```

Now the caller gets readable, self-documenting code:

```go
pair, err := netkit.CreatePair("nk0",
    netkit.WithL3Mode(),
    netkit.WithNoScrub(),
)
```

The `CreatePair` function applies these options to sensible defaults:

```go title="netkit/netkit.go"
package netkit

import (
    "fmt"

    "github.com/vishvananda/netlink"
)

type Pair struct {
    Primary    netlink.Link
    Peer       netlink.Link
    PrimaryIdx int
    PeerIdx    int
}

func CreatePair(name string, opts ...Option) (*Pair, error) {
    if name == "" {
        return nil, fmt.Errorf("netkit: device name cannot be empty")
    }

    cfg := defaultConfig()
    for _, opt := range opts {
        opt(cfg)
    }

    // Create netkit link
    attrs := netlink.NewLinkAttrs()
    attrs.Name = name

    // Peer naming convention: "nk0" -> "nk0p"
    peerName := name + "p"
    peerAttrs := netlink.NewLinkAttrs()
    peerAttrs.Name = peerName

    primary := &netlink.Netkit{
        LinkAttrs: attrs,
        Mode:      cfg.mode,
        Scrub:     cfg.scrubPrimary,
        PeerScrub: cfg.scrubPeer,
    }
    primary.SetPeerAttrs(&peerAttrs)

    if err := netlink.LinkAdd(primary); err != nil {
        return nil, fmt.Errorf("netkit: failed to create primary %q: %w", name, err)
    }

    // Setup cleanup in case of failure
    var cleanupPrimary = true
    defer func() {
        if cleanupPrimary {
            netlink.LinkDel(primary)
        }
    }()

    // Get the peer link (created automatically)
    peer, err := netlink.LinkByName(peerName)
    if err != nil {
        return nil, fmt.Errorf("netkit: failed to find peer %q: %w", peerName, err)
    }

    // Bring up both interfaces
    if err := netlink.LinkSetUp(primary); err != nil {
        return nil, fmt.Errorf("netkit: failed to bring up primary: %w", err)
    }

    if err := netlink.LinkSetUp(peer); err != nil {
        return nil, fmt.Errorf("netkit: failed to bring up peer: %w", err)
    }

    cleanupPrimary = false

    return &Pair{
        Primary:    primary,
        Peer:       peer,
        PrimaryIdx: primary.Attrs().Index,
        PeerIdx:    peer.Attrs().Index,
    }, nil
}
```

**Why the cleanup guard?** If any step fails after creating the primary (finding peer, bringing up interfaces), we need to delete the primary to avoid leaving orphan devices. The `cleanupPrimary` boolean prevents cleanup when everything succeeds.

## Step 3: Adding IPv6 Link-Local Addresses

Our interfaces need IP addresses to send and receive traffic. For a test environment, IPv6 link-local addresses (fe80::/64) are perfect: they're automatically scoped to the interface and don't require coordination with external networks.

Why random Interface IDs? Traditional link-local addresses derive the Interface ID from the MAC address using EUI-64. But netkit devices in L3 mode may not have real MAC addresses. Random IIDs work universally:

```go title="netkit/ipv6.go"
package netkit

import (
    "crypto/rand"
    "fmt"
    "net"

    "github.com/vishvananda/netlink"
)

func (p *Pair) ConfigureIPv6LinkLocal() error {
    if err := p.assignLinkLocal(p.Primary); err != nil {
        return fmt.Errorf("primary: %w", err)
    }

    if err := p.assignLinkLocal(p.Peer); err != nil {
        return fmt.Errorf("peer: %w", err)
    }

    return nil
}

func (p *Pair) assignLinkLocal(link netlink.Link) error {
    addr, err := generateLinkLocalAddr()
    if err != nil {
        return err
    }

    nlAddr := &netlink.Addr{
        IPNet: &net.IPNet{
            IP:   addr,
            Mask: net.CIDRMask(64, 128),
        },
    }

    if err := netlink.AddrAdd(link, nlAddr); err != nil {
        return fmt.Errorf("failed to add address: %w", err)
    }

    return nil
}

func generateLinkLocalAddr() (net.IP, error) {
    // fe80::/64 prefix
    addr := make(net.IP, 16)
    addr[0] = 0xfe
    addr[1] = 0x80

    // Random Interface ID (last 64 bits)
    iid := make([]byte, 8)
    if _, err := rand.Read(iid); err != nil {
        return nil, fmt.Errorf("failed to generate random IID: %w", err)
    }

    copy(addr[8:], iid)
    return addr, nil
}
```

Now our netkit pair has routable IPv6 addresses on both interfaces.

## Step 4: Writing the eBPF Program

Here's where the real monitoring happens. Our eBPF program runs in the kernel, inspects every IPv6 packet, and sends metadata to userspace through a ring buffer.

### CO-RE: Write Once, Run Everywhere

One of eBPF's biggest challenges is kernel compatibility. Internal structures change between versions. A field at offset 24 in kernel 6.1 might be at offset 32 in kernel 6.8.

CO-RE (Compile Once - Run Everywhere) solves this using BTF (BPF Type Format) information embedded in modern kernels. When you compile with debug info (`-g`), the compiler records which fields you're accessing. At load time, cilium/ebpf relocates these accesses to match the running kernel.

Instead of including dozens of kernel headers, we use `vmlinux.h` - a single file generated from BTF containing every kernel type:

```c title="bytecode/netkit_ipv6.c"
//go:build ignore

#include "vmlinux.h"
#include <linux/if_link.h>
#include <linux/if_ether.h>
#include <bpf/bpf_helpers.h>
#include <bpf/bpf_endian.h>
#include <bpf/bpf_core_read.h>
```

### The Event Structure

We need to define what data we send to userspace. The structure must be packed to ensure consistent memory layout:

```c title="bytecode/netkit_ipv6.c"
struct ipv6_event {
    __u8 src_addr[16];     // bytes 0-15
    __u8 dst_addr[16];     // bytes 16-31
    __u8 next_header;      // byte 32
    __u16 payload_len;     // bytes 33-34
    __u8 hop_limit;        // byte 35
    __u8 direction;        // byte 36
} __attribute__((packed));  // Total: 37 bytes
```

**Why packed?** Without `__attribute__((packed))`, the compiler may insert padding for alignment. This would waste space and cause Go to parse wrong offsets.

### Ring Buffer for Events

Ring buffers (introduced in kernel 5.8) are the preferred way to send data from kernel to userspace. They're more efficient than perf buffers: single shared buffer instead of per-CPU, preserved event ordering, and native support for variable-size events.

```c title="bytecode/netkit_ipv6.c"
struct {
    __uint(type, BPF_MAP_TYPE_RINGBUF);
    __uint(max_entries, 256 * 1024);  // 256KB buffer
} ipv6_events SEC(".maps");
```

### Packet Processing

The core logic parses IPv6 headers and sends events:

```c title="bytecode/netkit_ipv6.c"
static __always_inline int process_ipv6(struct __sk_buff *skb, __u8 direction) {
    void *data_end = (void *)(long)skb->data_end;
    void *data = (void *)(long)skb->data;

    struct ethhdr *eth = data;

    // Bounds check for Ethernet header
    if ((void *)(eth + 1) > data_end)
        return NETKIT_PASS;

    // Check for IPv6 (ethertype 0x86DD)
    if (eth->h_proto != bpf_htons(ETH_P_IPV6))
        return NETKIT_PASS;

    struct ipv6hdr *ip6 = (void *)(eth + 1);

    // Bounds check for IPv6 header
    if ((void *)(ip6 + 1) > data_end)
        return NETKIT_PASS;

    // Reserve space in ringbuf
    struct ipv6_event *event = bpf_ringbuf_reserve(&ipv6_events,
                                                    sizeof(*event), 0);
    if (!event)
        return NETKIT_PASS;

    // Copy IPv6 data using CO-RE reads
    __builtin_memcpy(event->src_addr, &ip6->saddr, 16);
    __builtin_memcpy(event->dst_addr, &ip6->daddr, 16);
    event->next_header = BPF_CORE_READ(ip6, nexthdr);
    event->payload_len = bpf_ntohs(BPF_CORE_READ(ip6, payload_len));
    event->hop_limit = BPF_CORE_READ(ip6, hop_limit);
    event->direction = direction;

    bpf_ringbuf_submit(event, 0);

    return NETKIT_PASS;
}
```

**Why bounds checks?** The eBPF verifier requires proof that every memory access is valid. Without `if ((void *)(ip6 + 1) > data_end)`, the verifier rejects the program with "invalid mem access".

**Why BPF_CORE_READ?** These macros generate BTF relocations for portable field access. `bpf_ntohs()` converts network byte order (big-endian) to host byte order.

### Attachment Points

Finally, we define the actual programs attached to primary and peer:

```c title="bytecode/netkit_ipv6.c"
SEC("netkit/primary")
int netkit_primary(struct __sk_buff *skb) {
    return process_ipv6(skb, 0);
}

SEC("netkit/peer")
int netkit_peer(struct __sk_buff *skb) {
    return process_ipv6(skb, 1);
}

char _license[] SEC("license") = "GPL";
```

The `SEC()` macro tells the kernel where to attach each program. The direction parameter (0 or 1) lets userspace distinguish traffic direction.

## Step 5: Loading and Attaching from Go

Now we connect everything in the userspace application. First, we use bpf2go to generate Go bindings from our C program:

```go title="bytecode/gen.go"
package bytecode

//go:generate go tool bpf2go -cc clang -cflags "-O2 -g -Wall -Werror" -target amd64,arm64 Netkit netkit_ipv6.c
```

Run `go generate ./bytecode` to compile the eBPF program and generate Go types.

The main application ties everything together:

```go title="main.go"
package main

import (
    "context"
    "encoding/binary"
    "flag"
    "fmt"
    "log"
    "net"
    "os/signal"
    "syscall"

    "github.com/cassamajor/xcnf/examples/netkit-ipv6/bytecode"
    "github.com/cassamajor/xcnf/examples/netkit-ipv6/netkit"

    "github.com/cilium/ebpf"
    "github.com/cilium/ebpf/link"
    "github.com/cilium/ebpf/ringbuf"
    "github.com/cilium/ebpf/rlimit"
)

func main() {
    deviceName := flag.String("name", "nk0", "Netkit device name")
    flag.Parse()

    if err := run(*deviceName); err != nil {
        log.Fatal(err)
    }
}

func run(deviceName string) error {
    // Remove memlock limit (required for eBPF maps)
    if err := rlimit.RemoveMemlock(); err != nil {
        return fmt.Errorf("removing memlock: %w", err)
    }

    // Create netkit pair
    log.Printf("Creating netkit pair %q...", deviceName)
    pair, err := netkit.CreatePair(deviceName, netkit.WithL3Mode())
    if err != nil {
        return fmt.Errorf("creating netkit pair: %w", err)
    }
    defer func() {
        log.Println("Deleting netkit pair...")
        pair.Delete()
    }()

    // Configure IPv6
    log.Println("Configuring IPv6 link-local addresses...")
    if err := pair.ConfigureIPv6LinkLocal(); err != nil {
        return fmt.Errorf("configuring IPv6: %w", err)
    }

    // Load eBPF objects
    log.Println("Loading eBPF programs...")
    var objs bytecode.NetkitObjects
    if err := bytecode.LoadNetkitObjects(&objs, nil); err != nil {
        return fmt.Errorf("loading eBPF objects: %w", err)
    }
    defer objs.Close()

    // Attach to primary interface
    log.Println("Attaching to primary interface...")
    primaryLink, err := link.AttachNetkit(link.NetkitOptions{
        Program:   objs.NetkitPrimary,
        Interface: pair.PrimaryIdx,
        Attach:    ebpf.AttachNetkitPrimary,
    })
    if err != nil {
        return fmt.Errorf("attaching primary: %w", err)
    }
    defer primaryLink.Close()

    // Attach to peer interface
    log.Println("Attaching to peer interface...")
    peerLink, err := link.AttachNetkit(link.NetkitOptions{
        Program:   objs.NetkitPeer,
        Interface: pair.PrimaryIdx,  // Note: still use PrimaryIdx
        Attach:    ebpf.AttachNetkitPeer,
    })
    if err != nil {
        return fmt.Errorf("attaching peer: %w", err)
    }
    defer peerLink.Close()

    // Open ringbuf reader
    rd, err := ringbuf.NewReader(objs.Ipv6Events)
    if err != nil {
        return fmt.Errorf("opening ringbuf: %w", err)
    }
    defer rd.Close()

    // Setup signal handling for graceful shutdown
    ctx, cancel := signal.NotifyContext(context.Background(),
        syscall.SIGINT, syscall.SIGTERM)
    defer cancel()

    log.Printf("Monitoring IPv6 traffic on %s (Ctrl+C to exit)", deviceName)

    // Read events
    go func() {
        for {
            record, err := rd.Read()
            if err != nil {
                return
            }
            printEvent(record.RawSample)
        }
    }()

    <-ctx.Done()
    log.Println("Shutting down...")
    return nil
}
```

**Why does peer attachment use PrimaryIdx?** This is a netkit API detail. Both programs attach via the primary interface index; the `Attach` constant (`AttachNetkitPrimary` vs `AttachNetkitPeer`) determines which hook point.

### Parsing Events

The `printEvent` function parses the raw bytes matching our C struct layout:

```go title="main.go"
func printEvent(data []byte) {
    if len(data) < 37 {
        return
    }

    var srcAddr, dstAddr [16]byte
    copy(srcAddr[:], data[0:16])
    copy(dstAddr[:], data[16:32])

    nextHeader := data[32]
    payloadLen := binary.LittleEndian.Uint16(data[33:35])
    hopLimit := data[35]
    direction := data[36]

    dirStr := "primary"
    if direction == 1 {
        dirStr = "peer"
    }

    fmt.Printf("[%s] IPv6: %s -> %s | next=%d len=%d ttl=%d\n",
        dirStr,
        net.IP(srcAddr[:]).String(),
        net.IP(dstAddr[:]).String(),
        nextHeader,
        payloadLen,
        hopLimit,
    )
}
```

**Why LittleEndian?** The eBPF program converted network byte order to host byte order with `bpf_ntohs()`. x86/ARM64 are little-endian, so we use `binary.LittleEndian`.

## Step 6: Resource Cleanup with defer

Go's `defer` executes in LIFO (last-in, first-out) order. This is exactly what we need: release resources in reverse order of acquisition.

Looking at our `run` function, the cleanup sequence is:

1. Close ringbuf reader (stop reading events)
2. Close peer link (detach peer eBPF program)
3. Close primary link (detach primary eBPF program)
4. Close eBPF objects (free kernel resources)
5. Delete netkit pair (remove interfaces)

**Why does order matter?** If we deleted the netkit pair before closing the eBPF links, the kernel would complain about attached programs on a deleted interface.

## Running the Monitor

Build and run:

```bash
# Generate eBPF bytecode
cd bytecode
bpftool btf dump file /sys/kernel/btf/vmlinux format c > vmlinux.h
cd ..
go generate ./bytecode

# Build and run
go build
sudo ./netkit-ipv6
```

In another terminal, generate IPv6 traffic:

```bash
ping6 ff02::1%nk0p
```

You'll see events like:

```
[peer] IPv6: fe80::a4b3:12ff:fe34:5678 -> ff02::1 | next=58 len=64 ttl=255
[primary] IPv6: fe80::2450:f8ea:df44:a99f -> ff02::2 | next=58 len=16 ttl=255
```

## Troubleshooting

**"operation not permitted"**: Need root privileges. Run with `sudo`.

**"unknown BPF map type"**: Kernel too old for ringbuf. Requires kernel 5.8+.

**"invalid mem access"**: Bounds check missing in eBPF program. Ensure every header access is guarded with a bounds check.

**"netkit not supported"**: Requires kernel 6.7+. Check with `uname -r`.

**No events logged**: Generate IPv6 traffic with `ping6 ff02::1%nk0p`. Verify interfaces are up with `ip link show`.

## What's Next?

This example demonstrates the foundation for building real CNF components. From here, you could:

- **Add packet filtering**: Use return values like `NETKIT_DROP` to implement firewall rules
- **Implement policy enforcement**: Make per-packet decisions based on source/destination
- **Add metrics collection**: Count packets by type, source, or protocol
- **Build a load balancer**: Redirect packets to different backends with `NETKIT_REDIRECT`

The complete source code is available at [github.com/cassamajor/xcnf/examples/netkit-ipv6](https://github.com/cassamajor/xcnf/tree/main/examples/netkit-ipv6).

## References

- [Netkit Kernel Documentation](https://docs.kernel.org/next/networking/netkit.html)
- [cilium/ebpf Library](https://github.com/cilium/ebpf)
- [vishvananda/netlink](https://github.com/vishvananda/netlink)
- [BPF CO-RE Reference Guide](https://nakryiko.com/posts/bpf-portability-and-co-re/)
